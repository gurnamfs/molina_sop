import os
from langchain_openai import AzureChatOpenAI
import yaml
from langchain_community.agent_toolkits import JsonToolkit, create_json_agent
from langchain_community.tools.json.tool import JsonSpec
from prompts import prefix, suffix, return_system_prompt
from dotenv import load_dotenv
from langchain_core.output_parsers import JsonOutputParser
from langchain_core.prompts import PromptTemplate
from pydantic import BaseModel, Field
import logging
# from langchain_core.globals import set_llm_cache
# from langchain_core.caches import InMemoryCache
from azure.storage.filedatalake import DataLakeServiceClient
# set_llm_cache(InMemoryCache())

load_dotenv()

API_KEY = os.getenv("API_KEY")
CONN_STR = os.getenv("CONN_STR_MOLINA")

service_client = DataLakeServiceClient.from_connection_string(conn_str = CONN_STR)

file_system_client = service_client.get_file_system_client("molina-bob-container")


logging.basicConfig(
    level=logging.INFO,  # You can change this to DEBUG or ERROR as needed
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler()
    ]
)



def azure_file_path(file_path):
    with open(file_path, "wb") as data:
        download = file_system_client.get_file_client(file_path).download_file()
        download.readinto(data)
    return file_path



llm = AzureChatOpenAI(
    azure_endpoint="https://firstsenseai.openai.azure.com",
    azure_deployment="gpt-4o",
    api_version="2024-02-15-preview",
    api_key=API_KEY,
    temperature=0,
    max_tokens=None,
)


model = AzureChatOpenAI(
    azure_endpoint="https://firstsenseai.openai.azure.com",
    azure_deployment="gpt432k",
    api_version="2024-05-01-preview",
    api_key=API_KEY,
    temperature=0,
    max_tokens=None,
)

class Format(BaseModel):
    file_path: str = Field(description="file_path in the text")
    query: str = Field(description="Exact process step to perform on the .json")

parser = JsonOutputParser(pydantic_object=Format)

prompt = PromptTemplate(
    template="Format the given text.\n{format_instructions}\n{text}\n",
    input_variables=["text"],
    partial_variables={"format_instructions": parser.get_format_instructions()},
)

chain = prompt | llm | parser



def initial_checks(claim):
    """
    The claim should be initially processed using the `initial_checks tool`, and
    the result from this tool should then be passed to the `create_agent tool`.

    Args:
        claim (str): A string representation of the claim.

    Returns:
        str: The processed claim to be passed on to the create_agent tool.
    """
    logging.info("###Initial Check Agent###")
    try:
        prompt = return_system_prompt + f"""`Claim`: {claim}"""
        
        res = llm.invoke(prompt)
        logging.info(f"Initial Checks response for claim: {res}")
        
        return res.content
    except Exception as e:
        logging.error(f"Error initial check: {e}")
        return "Function Initial Checks Failed"


# def final(claim):
#     """
#     Create an agent to extract relevant information from Timely Filing Document.

#     Args:
#         claim (str): The Claim to be processed by the agent.

#     Returns:
#         str: The response generated by the agent based on the provided query.
#     """
#     logging.info("###Timely Filing Tool###")

#     try:
#         new_file_path = azure_file_path("Timely Filing Requirements by State Job Aid.json")
#         with open(new_file_path) as f:
#             data = yaml.load(f, Loader=yaml.FullLoader)
#             logging.debug(f"Loaded data from JSON file Successfully")
#         json_spec = JsonSpec(dict_=data, max_value_length=4000)
#         json_toolkit = JsonToolkit(spec=json_spec)

#         json_agent_executor = create_json_agent(
#             handle_parsing_errors=True,
#             prefix=prefix,
#             suffix=suffix,
#             llm=model,
#             toolkit=json_toolkit,
#             verbose=True,
#             agent_kwargs = {
#                 'handle_parsing_errors' : True

#             }
#         )

#         response = json_agent_executor.invoke(
#             "Extract only the information related to timely filing for the specified State:\n" + claim
#         )
#         logging.info(f"Received Timely Filing response")
#         os.remove(new_file_path)

#         return response
#     except Exception as e:
#         logging.error(f"Error Timely Filing: {e}")
#         return "Error in Timely Filing"