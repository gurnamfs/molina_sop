import os
from langchain_openai import AzureChatOpenAI
import yaml
from langchain_community.agent_toolkits import JsonToolkit, create_json_agent
from langchain_community.tools.json.tool import JsonSpec
from prompts import prefix, suffix, return_system_prompt
from dotenv import load_dotenv
from langchain_core.output_parsers import JsonOutputParser
from langchain_core.prompts import PromptTemplate
from pydantic import BaseModel, Field
import logging

logging.basicConfig(
    level=logging.INFO,  # You can change this to DEBUG or ERROR as needed
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler()
    ]
)



load_dotenv()

API_KEY = os.getenv("API_KEY")



llm = AzureChatOpenAI(
    azure_endpoint="https://firstsenseai.openai.azure.com",
    azure_deployment="gpt-4o",
    api_version="2024-02-15-preview",
    api_key=API_KEY,
    temperature=0,
    max_tokens=None,
)

model = AzureChatOpenAI(
    azure_endpoint="https://firstsenseai.openai.azure.com",
    azure_deployment="gpt432k",
    api_version="2024-05-01-preview",
    api_key=API_KEY,
    temperature=0,
    max_tokens=None,
)

class Format(BaseModel):
    file_path: str = Field(description="file_path in the text")
    query: str = Field(description="Exact process step to perform on the .json")

parser = JsonOutputParser(pydantic_object=Format)

prompt = PromptTemplate(
    template="Format the given text.\n{format_instructions}\n{text}\n",
    input_variables=["text"],
    partial_variables={"format_instructions": parser.get_format_instructions()},
)

chain = prompt | llm | parser



def initial_checks(claim):
    """
    The claim should be initially processed using the `initial_checks tool`, and
    the result from this tool should then be passed to the `create_agent tool`.

    Args:
        claim (str): A string representation of the claim.

    Returns:
        str: The processed claim to be passed on to the create_agent tool.
    """
    logging.info("###Initial Check Agent###")
    try:
        prompt = return_system_prompt + f"""`Claim`: {claim}"""
        
        res = llm.invoke(prompt).content
        logging.info(f"Initial Checks response for claim: {res}")
        
        return res
    except Exception as e:
        logging.error(f"Error initial check: {e}")
        return "Function Initial Checks Failed"


def final(claim):
    """
    Create an agent to extract relevant information from Timely Filing Document.

    Args:
        claim (str): The Claim to be processed by the agent.

    Returns:
        str: The response generated by the agent based on the provided query.
    """
    logging.info("###Timely Filing Tool###")

    try:
        with open("json-files/Timely Filing Requirements by State Job Aid.json") as f:
            data = yaml.load(f, Loader=yaml.FullLoader)
            logging.debug(f"Loaded data from JSON file Successfully")
        json_spec = JsonSpec(dict_=data, max_value_length=4000)
        json_toolkit = JsonToolkit(spec=json_spec)

        json_agent_executor = create_json_agent(
            handle_parsing_errors=True,
            prefix=prefix,
            suffix=suffix,
            llm=model,
            toolkit=json_toolkit,
            verbose=True,
        )

        response = json_agent_executor.invoke(
            "Extract only the information related to the specified State: " + claim + "\n\nNote: Return data for timely filing without any extra information."
        )
        logging.info(f"Received Timely Filing response")

        return response
    except Exception as e:
        logging.error(f"Error Timely Filing: {e}")
        return "Error in Timely Filing"